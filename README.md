<br>
<p align="center">
  <img src="https://huergo.edu.ar/images/convenios/fiuba.jpg" width="100%" style="background-color:white"/>
</p>

# â˜• Coffee Shop Analysis

## ğŸ“š Materia: Sistemas Distribuidos 1 (Roca)

## ğŸ‘¥ Grupo 9

### Integrantes

| Nombre                                                          | PadrÃ³n |
| --------------------------------------------------------------- | ------ |
| [Ascencio Felipe Santino](https://github.com/FelipeAscencio)    | 110675 |
| [Gamberale Luciano MartÃ­n](https://github.com/lucianogamberale) | 105892 |
| [Zielonka Axel](https://github.com/axel-zielonka)               | 110310 |

### Corrector

- [Franco Papa](https://github.com/F-Papa)

## ğŸ“– DescripciÃ³n

Este repositorio contiene el material del TP del sistema distribuido "Coffee Shop Analysis", correspondiente al segundo cuatrimestre del aÃ±o 2025 en la materia Sistemas Distribuidos 1 (Roca).

## ğŸ› ï¸ Informe de DiseÃ±o

El informe tÃ©cnico incluye:
- Decisiones de diseÃ±o.
- ImplementaciÃ³n de cada ejercicio.
- Protocolo de comunicaciÃ³n.
- Mecanismos de concurrencia utilizados.
- Instrucciones de ejecuciÃ³n.
- Mecanismos de control de fallas.
- Herramienta de creaciÃ³n de fallas.

[ğŸ“‘ Acceso al informe](./docs/Informe-G9-DiseÃ±o.pdf).

## ğŸ§° GuÃ­a rÃ¡pida de uso con `Makefile`

### ğŸš€ EjecuciÃ³n del Sistema con Docker Compose

En este TP se utiliza **Docker Compose** para levantar todos los componentes del sistema distribuido:
- El **cliente** que realiza las queries.
- El **servidor** que las recibe.
- Todos los **nodos** del sistema distribuido.
- El **middleware**.

#### âš™ï¸ Construir las imÃ¡genes Docker

Antes de levantar el sistema, es posible (aunque no obligatorio) construir manualmente todas las imÃ¡genes Docker definidas dentro del proyecto.

```bash

make docker-build-image

```

ğŸ”§ Este comando busca automÃ¡ticamente todos los Dockerfile dentro de src/, los construye y los etiqueta con el nombre del directorio correspondiente.

ğŸ’¡ No es necesario ejecutarlo manualmente, ya que make docker-compose-up lo ejecuta automÃ¡ticamente antes de levantar los contenedores.

#### â–¶ï¸ Levantar todo el sistema

```bash

make docker-compose-up

```

âœ… Este comando pone en marcha todos los servicios del sistema distribuido (cliente, servidor, nodos y middleware).

AdemÃ¡s, se asegura de reconstruir imÃ¡genes si detecta cambios y elimina contenedores huÃ©rfanos de ejecuciones anteriores.

#### â¹ï¸ Apagar todo el sistema

```bash

make docker-compose-down

```

âŒ Detiene todos los servicios activos y elimina los contenedores, liberando los recursos utilizados.

El sistema quedarÃ¡ completamente detenido y en un estado limpio.

#### ğŸ“œ Ver los logs del sistema

```bash

make docker-compose-logs

```

ğŸ‘€ Muestra en consola los Ãºltimos 500 registros de cada contenedor y mantiene el seguimiento en tiempo real (-f).

Ideal para monitorear el comportamiento de los componentes durante la ejecuciÃ³n.

#### ğŸ” Filtrar logs de un contenedor especÃ­fico

```bash

make docker-compose-logs | grep '<nombre_del_contenedor>'

```

ğŸ‘‰ Permite filtrar los logs para enfocarse en un componente en particular, por ejemplo los filters del sistema.

##### Ejemplo

```bash

make docker-compose-logs | grep 'filter'

```

### ğŸ§ª Testing

El Makefile incluye un conjunto de herramientas de testing para verificar el correcto funcionamiento del sistema distribuido.

#### ğŸ§± Tests unitarios de funcionamiento del Middleware

```bash

make unit-tests

```

ğŸ” Ejecuta los tests unitarios definidos con pytest en modo detallado (--verbose).

Estos tests suelen enfocarse en el middleware u otras partes especÃ­ficas del sistema.

##### ğŸ§© ConsideraciÃ³n

Los **tests unitarios** se ejecutan siempre dentro del entorno de desarrollo basado en **Dev Containers**.  

Este enfoque garantiza un ambiente de ejecuciÃ³n **aislado, reproducible y controlado**, evitando inconsistencias entre configuraciones locales.  

PodÃ©s consultar mÃ¡s informaciÃ³n sobre Dev Containers en la documentaciÃ³n oficial de Visual Studio Code:  

ğŸ”— [https://code.visualstudio.com/docs/devcontainers/containers](https://code.visualstudio.com/docs/devcontainers/containers)

Para ejecutar correctamente estos tests, es necesario realizar una pequeÃ±a modificaciÃ³n previa:

1. AccedÃ© al archivo `docker-compose-dev.yaml` ubicado dentro del directorio `.devcontainer/`.
2. **DescomentÃ¡ las lÃ­neas correspondientes al servicio de RabbitMQ** destinado al entorno de pruebas.
3. Al hacerlo, se levantarÃ¡ **una instancia independiente de RabbitMQ** utilizada exclusivamente para la ejecuciÃ³n de los tests unitarios dentro del contenedor de desarrollo.

Estas lÃ­neas permanecen **comentadas por defecto** para evitar conflictos o sobrecargas con el **RabbitMQ principal** que se utiliza durante la ejecuciÃ³n normal del sistema distribuido.

De este modo, se evita que las pruebas interfieran con los procesos del sistema en funcionamiento o afecten el rendimiento general.

Esta configuraciÃ³n permite que los tests unitarios del middleware se ejecuten en un entorno completamente controlado,  
logrando un **nivel Ã³ptimo de aislamiento y fiabilidad**, y asegurando que los resultados de las pruebas reflejen con precisiÃ³n el comportamiento del middleware sin depender del estado del sistema completo.

#### ğŸ”— Tests de integraciÃ³n

```bash

make integration-tests EXPECTED_VARIANT=<output_a_validar>

```

ğŸ§© Este comando ejecuta el conjunto de tests de integraciÃ³n, comparando las salidas generadas por el sistema contra los resultados esperados.

El proceso incluye los siguientes pasos:

1. Copia y normaliza (mediante ordenamiento) los archivos generados por el sistema en '.results/query_results/'.

2. Guarda los resultados actuales en 'integration-tests/data/query_results/'.

3. Compara los resultados normalizados con los outputs esperados definidos en:

```bash

integration-tests/data/expected_output/<EXPECTED_VARIANT>/

```

4. Reporta las diferencias detectadas (si es que las hay) para cada consulta.

ObservaciÃ³n: Los tests de integraciÃ³n deben de ser ejecutados luego de haber utilizado el Sistema Distribuido con un Ãºnico cliente.

Esto para garantizar la correcta validaciÃ³n de la respuesta generada a cada una de las consultas de un Ãºnico usuario.

##### Ejemplo con 'reduced_data'

```bash

make integration-tests

```

ObservaciÃ³n: No hace falta asignar la variable, se pasa el valor 'reduced_data' por defecto.

##### Ejemplo con 'full_data'

```bash

make integration-tests EXPECTED_VARIANT=full_data

```

#### ğŸ§ª Tests de propagaciÃ³n EOF

El sistema cuenta con una baterÃ­a de tests para verificar la correcta propagaciÃ³n de los EOF entre los nodos, asegurando un cierre coordinado del flujo de datos en escenarios multi-cliente.

##### Paso 1 - Exportar logs

```bash

make docker-export-logs

```

ğŸ“‚ Este comando genera un directorio 'logs/' en el cual se almacenan los logs de cada servicio que contengan el tÃ©rmino eof.

Cada archivo tiene el formato 'logs/<servicio>.log' y permite validar el flujo de finalizaciÃ³n de datos en los componentes distribuidos.

Una vez hecho este paso se debe realizar una ejecuciÃ³n completa de uno o mas clientes en el Sistema Distribuido. Para luego avanzar al siguiente paso.

##### Paso 2 - Ejecutar validaciÃ³n de EOF

```bash

make test-all-eof-received

```

âœ… Ejecuta el script 'eof_test.py', encargado de analizar los logs exportados y verificar que todos los nodos hayan recibido correctamente las seÃ±ales de finalizaciÃ³n (EOF).

De este modo, se puede corroborar la correcta implementaciÃ³n del mecanismo de finalizaciÃ³n y la sincronizaciÃ³n entre los distintos componentes del Sistema Distribuido.

## ğŸ“¡ Monitorear RabbitMQ

Dado que el sistema utiliza RabbitMQ para la comunicaciÃ³n, podÃ©s seguir en tiempo real el estado de las colas, los mensajes que viajan y cÃ³mo se encadenan los procesos.

1. Primero, asegurate de haber levantado el sistema con make docker-compose-up.
2. Luego, entrÃ¡ a la siguiente URL en tu navegador: [ğŸ”— Link al gestor web](http://localhost:15672/)

### ğŸ“Œ Credenciales por defecto:

- Usuario: guest
- ContraseÃ±a: guest

### Â¿QuÃ© nos permite hacer la interfaz del gestor?

Esta interfaz nos permite:

- Ver las colas activas.
- Inspeccionar mensajes.
- Observar cÃ³mo los controladores intercambian informaciÃ³n.

## ğŸµ Chaos-Monkey (Herramienta de creaciÃ³n de fallas)

Para generar fallos en el sistema distribuido (Ya sea de forma manual o automÃ¡tica) se desarrollÃ³ una herramienta de generacion de fallas del estilo 'Chaos-Monkey'.

Dentro del directorio 'chaos_monkey', se encuentra un 'README.md' con una explicaciÃ³n completa acerca de las configuraciones, uso y modos de funcionamiento de la misma.

## ğŸ“ Archivos de entrada y salida

El sistema funciona con archivos de entrada y salida, se pasa a detallar el funcionamiento y ubicaciÃ³n de cada uno.

A continuaciÃ³n se pasa a detallar el funcionamiento al trabajar con el dataset completo.

### Archivos de entrada

Residen en el directorio ".data", estos son los que envÃ­a el cliente junto con las queries, y le brindan al sistema los datos para realizar el procesamiento pedido.

Por motivos de tamaÃ±o excesivo no se pueden cargas los datasets directamente en el repositorio, por lo que deben cargarse manualmente.

Para descargar el dataset completo se debe ingresar al siguiente link: [ğŸ”— Link al dataset completo](https://www.kaggle.com/datasets/geraldooizx/g-coffee-shop-transaction-202307-to-202506/data)

TambiÃ©n generamos nuestro propio dataset reducido (30%): [ğŸ”— Link al dataset reducido](https://drive.google.com/drive/folders/1Zx6vl8iXw10OIUKS5Iz3qadV2ro_gW3f?usp=sharing)

### Archivos de salida

Las respuestas a las queries se generarÃ¡n en archivos separados por cada una, que se crearÃ¡n dentro del directorio '.results/query_results'.

Al finalizar la ejecuciÃ³n completa del procesamiento para todas las queries, dentro de ese directorio encontraremos el reporte final con los resultados para cada consulta realizada por el cliente.

## â™»ï¸ Configuraciones del ambiente ('.env')

A fin de optimizar y modularizar el funcionamiento del sistema, se utiliza la herramienta del archivo '.env' para definir variables como:
- Rutas de donde los clientes obtienen los archivos de entrada.
- Cantidad de nodos instanciados por cada controlador.
- TamaÃ±o de los 'Batchs' a enviar por cada mensaje.
- Credenciales de 'RabbitMQ'.
- LOGGING LEVEL.

Con esto se consiguiÃ³ desacoplar el sistema lo mÃ¡ximo posible, y conseguir una Ã³ptima abstracciÃ³n y separaciÃ³n de responsabilidades en la implementaciÃ³n.

AdemÃ¡s, se elaborÃ³ un script que permite generar de forma automÃ¡tica el archivo 'docker-compose.yaml' en base a las variables de entorno definidas en el archivo.

Para ejecutar el mismo se debe utilizar el siguente comando:

```bash

./generar-compose.sh docker-compose.yaml

```

## ğŸ¥ DesmotraciÃ³n de funcionamiento

[ğŸ”— Link al video tutorial de funcionamiento](https://drive.google.com/drive/folders/1iDnXWh1Dd8fJBw4gxLcIzglYpP3rrnXQ?usp=sharing)
